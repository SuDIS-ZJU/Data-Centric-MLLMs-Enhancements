# Awesome LVLM Data Quality [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

**"Data Quality in Large Vision-Language Models: An ARC Framework and Diagnostic Perspective"** (2025).  

We aim to provide a **living handbook** for researchers and practitioners interested in the **data-centric development of Large Visionâ€“Language Models (LVLMs)**.  
The repository will be continuously updated with new references, datasets, and tools.



## ðŸ“Œ Contents
1. [Introduction](#introduction)
2. [ARC Framework](#arc-framework)
3. [Data Issues (11 representative issues)](#data-issues-11-representative-issues)
4. [Diagnosis Framework](#diagnosis-framework)
5. [Paper Map (Annotated Table)](#paper-map-annotated-table)
6. [Summary: Trends & Future Directions](#summary-trends--future-directions)
7. [Resources](#resources)
8. [Contributing](#contributing)

## Introduction

A living handbook accompanying our survey *Data Quality in LVLMs: An ARC Framework and Diagnostic Perspective*.  
We focus on **data-centric** challenges and solutions for **Large Visionâ€“Language Models (LVLMs)**, and maintain an evolving repository of papers, datasets, and tools.


Our goal is to systematically review and categorize recent works that highlight data-centric methodologies for:
- Improving model generalization
- Enhancing multimodal alignment
- Ensuring safety and fairness
- Handling data noise and imbalance

## ARC Framework
**A**vailability â€” scale, coverage, accessibility (data layer)  
**R**eliability â€” semantic fidelity, alignment, balance (semantic layer)  
**C**redibility â€” trust, safety, privacy (application layer)  
ARC provides both a **taxonomy** and a **diagnostic lens** to map symptoms â†’ root causes â†’ remedies.

## Key Papers

Here is a selection of key papers reviewed in this repository:

1. **Paper Title 1**  
   *Authors*: A. Author, B. Author  
   *Summary*: A comprehensive overview of data-centric techniques for improving vision-language alignment in MLLMs. [Link to paper](https://example.com)

2. **Paper Title 2**  
   *Authors*: C. Author, D. Author  
   *Summary*: This paper focuses on noise-robust training methodologies for multimodal models by curating high-quality datasets. [Link to paper](https://example.com)

3. **Paper Title 3**  
   *Authors*: E. Author, F. Author  
   *Summary*: A study on the impact of fine-tuning with curated safety datasets to prevent harmful content generation in MLLMs. [Link to paper](https://example.com)

_For a full list of papers, see the [papers](./papers) directory._

## Datasets

We review and compile several datasets relevant to data-centric MLLM training and evaluation. Some examples include:

1. **Dataset Name 1**  
   Description: A large-scale multimodal dataset for image-captioning tasks.  
   [Link to dataset](https://example.com)

2. **Dataset Name 2**  
   Description: A benchmark dataset for evaluating safety and fairness in vision-language models.  
   [Link to dataset](https://example.com)

_Refer to the [datasets](./datasets) directory for detailed descriptions and links._

## Contributing

Contributions are welcome! If you have relevant papers, datasets, or scripts that align with the theme of this repository, feel free to open a pull request or raise an issue.

Please make sure to follow these guidelines when contributing:
1. Fork the repository.
2. Create a new branch for your changes.
3. Ensure your contribution is relevant to data-centric approaches in MLLMs.
4. Submit a pull request for review.

## License

This repository is licensed under the MIT License. See the [LICENSE](./LICENSE) file for more details.
